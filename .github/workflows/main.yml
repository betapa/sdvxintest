name: SDVX 모든 레벨 스크래핑 및 Notion 갱신

on:
  # 1. 매일 0시(UTC)에 자동으로 실행 (한국 시간 오전 9시)
  schedule:
    - cron: '0 0 * * *'
  
  # 2. GitHub Actions 탭에서 수동으로 실행 가능하도록 설정
  workflow_dispatch:

jobs:
  scrape-and-update:
    runs-on: ubuntu-latest

    steps:
      # 1. 리포지토리의 코드를 runner로 가져옴 (Python 스크립트 포함)
      - name: Checkout repository
        uses: actions/checkout@v4

      # 2. Python 3.10 환경 설정
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'

      # 3. 필요한 Python 라이브러리 설치
      # (requests, beautifulsoup4, notion-client)
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install requests beautifulsoup4 notion-client

      # 4. 스크래핑 및 Notion 갱신 스크립트 실행
      - name: Run Python script
        env:
          # 3단계에서 설정한 GitHub Secrets를 스크립트의 환경 변수로 주입
          NOTION_API_KEY: ${{ secrets.NOTION_API_KEY }}
          DATABASE_ID: ${{ secrets.DATABASE_ID }}
        run: |
          python scrap.py # 2단계에서 저장한 Python 스크립트 파일명
