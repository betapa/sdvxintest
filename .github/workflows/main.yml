name: SDVX 모든 레벨 스크래핑 및 Notion 갱신

on:
  # 1. 매일 0시(UTC)에 자동으로 실행 (한국 시간 오전 9시)
  schedule:
    - cron: '0 0 * * *'
  
  # 2. GitHub Actions 탭에서 수동으로 실행 가능하도록 설정
  workflow_dispatch:

jobs:
  scrape-and-update:
    runs-on: ubuntu-latest

    steps:
      # 1. 리포지토리의 코드를 runner로 가져옴 (Python 스크립트 포함)
      - name: Checkout repository
        uses: actions/checkout@v4

      # 2. Python 3.10 환경 설정
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'

      # 3. 필요한 Python 라이브러리 설치 (캐시 삭제 포함)
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          # (추가) 혹시 모를 이전 버전 강제 삭제
          python -m pip uninstall -y notion-client
          # (추가) pip 캐시 강제 삭제
          python -m pip cache purge
          # (수정) --no-cache-dir 추가하여 캐시 사용 방지
          python -m pip install --no-cache-dir --upgrade requests beautifulsoup4 "notion-client>=1.0.0"

      # 4. (추가) 설치된 버전을 확인하여 디버깅합니다.
      - name: Check installed notion-client version
        run: |
          echo "Verifying installed notion-client version:"
          python -m pip show notion-client
          
      # 5. 스크래핑 및 Notion 갱신 스크립트 실행 (이전 4단계)
      - name: Run Python script
        env:
          # GitHub Secrets를 스크립트의 환경 변수로 주입
          NOTION_API_KEY: ${{ secrets.NOTION_API_KEY }}
          DATABASE_ID: ${{ secrets.DATABASE_ID }}
        run: |
          # yml 파일에 정의된 대로 'scrap.py'를 실행합니다.
          python scrap.py
